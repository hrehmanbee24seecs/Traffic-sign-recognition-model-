{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrehmanbee24seecs/Traffic-sign-recognition-model-/blob/main/Traffic_sign_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPSJRsvYfzZe"
      },
      "source": [
        "# Traffic Sign Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcqdN6jIgfc_"
      },
      "source": [
        "## File handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwTsvpT68KU9",
        "outputId": "31ac5fe9-e2eb-4ff3-e3a1-d3660a56f079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracting ZIP...\n",
            "7z stdout:\n",
            " \n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,24 CPUs AMD EPYC 7B13 (A00F10),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "1 file, 199059936 bytes (190 MiB)\n",
            "\n",
            "Extracting archive: /content/drive/MyDrive/archive (11).zip\n",
            "--\n",
            "Path = /content/drive/MyDrive/archive (11).zip\n",
            "Type = zip\n",
            "Physical Size = 199059936\n",
            "\n",
            "Everything is Ok\n",
            "\n",
            "Files: 6165\n",
            "Size:       197906082\n",
            "Compressed: 199059936\n",
            "\n",
            "7z stderr:\n",
            " \n",
            "✅ Found dataset at: /content/traffic_Data\n",
            "✅ TRAIN_DIR: /content/traffic_Data/DATA\n",
            "✅ TEST_DIR : /content/traffic_Data/TEST\n",
            "\n",
            "Top-level contents of traffic_Data:\n",
            "['DATA', 'TEST']\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# Robust ZIP extraction + dataset discovery\n",
        "# ===============================\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os, subprocess\n",
        "\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/archive (11).zip\"\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "# 1. Ensure 7z exists\n",
        "run(\"apt-get update -qq\")\n",
        "run(\"apt-get install -y p7zip-full -qq\")\n",
        "\n",
        "# 2. Extract ZIP into /content (fast)\n",
        "print(\"Extracting ZIP...\")\n",
        "res = run(f'7z x \"{ZIP_PATH}\" -o\"/content\" -y')\n",
        "print(\"7z stdout:\\n\", res.stdout)\n",
        "print(\"7z stderr:\\n\", res.stderr)\n",
        "\n",
        "# 3. Find traffic_Data directory automatically\n",
        "def find_traffic_data(root=\"/content\"):\n",
        "    for r, d, f in os.walk(root):\n",
        "        if \"traffic_Data\" in d:\n",
        "            return os.path.join(r, \"traffic_Data\")\n",
        "    return None\n",
        "\n",
        "DATA_DIR = find_traffic_data(\"/content\")\n",
        "\n",
        "if DATA_DIR is None:\n",
        "    raise RuntimeError(\"❌ Could not find 'traffic_Data' folder after extraction.\")\n",
        "\n",
        "print(\"✅ Found dataset at:\", DATA_DIR)\n",
        "\n",
        "# 4. Final paths\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"DATA\")\n",
        "TEST_DIR  = os.path.join(DATA_DIR, \"TEST\")\n",
        "\n",
        "if not (os.path.isdir(TRAIN_DIR) and os.path.isdir(TEST_DIR)):\n",
        "    raise RuntimeError(\"❌ 'DATA' or 'TEST' folders missing inside traffic_Data.\")\n",
        "\n",
        "print(\"✅ TRAIN_DIR:\", TRAIN_DIR)\n",
        "print(\"✅ TEST_DIR :\", TEST_DIR)\n",
        "\n",
        "# 5. Quick sanity listing\n",
        "print(\"\\nTop-level contents of traffic_Data:\")\n",
        "print(os.listdir(DATA_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OoNTufkNo_Pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b1bb1a-0d94-485a-f183-f20cc60bd799"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaSLNeJHgmOy"
      },
      "source": [
        "## imports and reproducibility settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwyTQ5x-7rHW",
        "outputId": "674a396b-b4a4-4a87-d612-db8e30f90104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting statsmodels\n",
            "  Downloading statsmodels-0.14.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Collecting patsy>=0.5.6 (from statsmodels)\n",
            "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m799.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsmodels-0.14.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorboard-data-server, patsy, opencv-python, google_pasta, tensorboard, astunparse, statsmodels, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.9.23 google_pasta-0.2.0 libclang-18.1.1 opencv-python-4.12.0.88 patsy-1.0.2 statsmodels-0.14.6 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.4 wheel-0.45.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enabled TF deterministic ops.\n",
            "TensorFlow version: 2.20.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow opencv-python statsmodels\n",
        "import random, numpy as np, tensorflow as tf, math, time, sys, os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from scipy import stats\n",
        "\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "# try enabling deterministic ops if available\n",
        "try:\n",
        "    tf.config.experimental.enable_op_determinism()\n",
        "    print(\"Enabled TF deterministic ops.\")\n",
        "except Exception as e:\n",
        "    print(\"TF deterministic not available or failed:\", e)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0BF3O-kgu2x"
      },
      "source": [
        "\n",
        "\n",
        "## Re-defining dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyEdNwvZ8uar",
        "outputId": "ba651c01-cea2-4215-d9f0-1f051fb450a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DATA_DIR   : /content/traffic_Data\n",
            "✅ ROOT_TRAIN: /content/traffic_Data/DATA\n",
            "✅ ROOT_TEST : /content/traffic_Data/TEST\n",
            "Train folders: 58\n",
            "Test files: 1994\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# This must point to the folder that CONTAINS traffic_Data\n",
        "BASE_EXTRACT_PATH = \"/content\"\n",
        "\n",
        "def find_traffic_data(root):\n",
        "    for r, d, f in os.walk(root):\n",
        "        if \"traffic_Data\" in d:\n",
        "            return os.path.join(r, \"traffic_Data\")\n",
        "    return None\n",
        "\n",
        "DATA_DIR = find_traffic_data(BASE_EXTRACT_PATH)\n",
        "\n",
        "if DATA_DIR is None:\n",
        "    raise RuntimeError(\"traffic_Data folder not found. Extraction may have failed.\")\n",
        "\n",
        "ROOT_TRAIN = os.path.join(DATA_DIR, \"DATA\")\n",
        "ROOT_TEST  = os.path.join(DATA_DIR, \"TEST\")\n",
        "\n",
        "print(\"✅ DATA_DIR   :\", DATA_DIR)\n",
        "print(\"✅ ROOT_TRAIN:\", ROOT_TRAIN)\n",
        "print(\"✅ ROOT_TEST :\", ROOT_TEST)\n",
        "\n",
        "# sanity check\n",
        "print(\"Train folders:\", len(os.listdir(ROOT_TRAIN)))\n",
        "print(\"Test files:\", len(os.listdir(ROOT_TEST)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VG85yGrhUwD"
      },
      "source": [
        "## Dataset loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFHwIclW8bnI",
        "outputId": "33bf41b3-1a5f-47e7-c857-ddef131cb7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 118 images for class 0\n",
            "Loaded 40 images for class 1\n",
            "Loaded 80 images for class 2\n",
            "Loaded 260 images for class 3\n",
            "Loaded 98 images for class 4\n",
            "Loaded 194 images for class 5\n",
            "Loaded 78 images for class 6\n",
            "Loaded 152 images for class 7\n",
            "Loaded 8 images for class 8\n",
            "Loaded 2 images for class 9\n",
            "Loaded 70 images for class 10\n",
            "Loaded 138 images for class 11\n",
            "Loaded 96 images for class 12\n",
            "Loaded 36 images for class 13\n",
            "Loaded 128 images for class 14\n",
            "Loaded 22 images for class 15\n",
            "Loaded 142 images for class 16\n",
            "Loaded 130 images for class 17\n",
            "Loaded 8 images for class 18\n",
            "Loaded 4 images for class 19\n",
            "Loaded 18 images for class 20\n",
            "Loaded 12 images for class 21\n",
            "Loaded 18 images for class 22\n",
            "Loaded 14 images for class 23\n",
            "Loaded 100 images for class 24\n",
            "Loaded 2 images for class 25\n",
            "Loaded 126 images for class 26\n",
            "Loaded 28 images for class 27\n",
            "Loaded 446 images for class 28\n",
            "Loaded 44 images for class 29\n",
            "Loaded 150 images for class 30\n",
            "Loaded 42 images for class 31\n",
            "Loaded 14 images for class 32\n",
            "Loaded 4 images for class 33\n",
            "Loaded 26 images for class 34\n",
            "Loaded 156 images for class 35\n",
            "Loaded 40 images for class 36\n",
            "Loaded 58 images for class 37\n",
            "Loaded 30 images for class 38\n",
            "Loaded 34 images for class 39\n",
            "Loaded 32 images for class 40\n",
            "Loaded 18 images for class 41\n",
            "Loaded 32 images for class 42\n",
            "Loaded 82 images for class 43\n",
            "Loaded 30 images for class 44\n",
            "Loaded 24 images for class 45\n",
            "Loaded 18 images for class 46\n",
            "Loaded 12 images for class 47\n",
            "Loaded 10 images for class 48\n",
            "Loaded 42 images for class 49\n",
            "Loaded 56 images for class 50\n",
            "Loaded 8 images for class 51\n",
            "Loaded 36 images for class 52\n",
            "Loaded 2 images for class 53\n",
            "Loaded 324 images for class 54\n",
            "Loaded 162 images for class 55\n",
            "Loaded 110 images for class 56\n",
            "Loaded 6 images for class 57\n",
            "Total samples: 4170\n",
            "Num classes: 58\n",
            "Some class counts (first 10): [('0', 118), ('1', 40), ('2', 80), ('3', 260), ('4', 98), ('5', 194), ('6', 78), ('7', 152), ('8', 8), ('9', 2)]\n",
            "Train shape: (3419, 64, 64, 3) (3419, 58) Val shape: (751, 64, 64, 3) (751, 58)\n",
            "Raw test samples: 1994 some inferred labels: [0 0 0 0 0 0 0 0 0 0]\n",
            "Test after mapping: 1994\n"
          ]
        }
      ],
      "source": [
        "# CELL 5: dataset loader (folder-based) with sanity checks\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "IMG_SIZE = 64\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "\n",
        "def list_class_folders(train_root):\n",
        "    # prefer numeric-sorted classes (0..)\n",
        "    folders = [d for d in os.listdir(train_root) if os.path.isdir(os.path.join(train_root,d))]\n",
        "    try:\n",
        "        folders = sorted(folders, key=lambda x: int(x))\n",
        "    except:\n",
        "        folders = sorted(folders)\n",
        "    return folders\n",
        "\n",
        "def load_images_from_folder(folder, img_size=IMG_SIZE):\n",
        "    imgs = []\n",
        "    fnames = []\n",
        "    for fn in sorted(os.listdir(folder)):\n",
        "        fp = os.path.join(folder, fn)\n",
        "        if not os.path.isfile(fp):\n",
        "            continue\n",
        "        try:\n",
        "            img = cv2.imdecode(np.fromfile(fp, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (img_size, img_size))\n",
        "            imgs.append(img)\n",
        "            fnames.append(fp)\n",
        "        except Exception as e:\n",
        "            print(\"Warning reading\", fp, \":\", e)\n",
        "    return imgs, fnames\n",
        "\n",
        "def build_train_dataset(train_root, img_size=IMG_SIZE):\n",
        "    class_folders = list_class_folders(train_root)\n",
        "    if len(class_folders) == 0:\n",
        "        raise ValueError(\"No class folders found in train root: \" + train_root)\n",
        "    label_map = {cls: idx for idx, cls in enumerate(class_folders)}\n",
        "    inv_map = {v:k for k,v in label_map.items()}\n",
        "    X=[]; y=[]\n",
        "    counts=[]\n",
        "    for cls in class_folders:\n",
        "        p = os.path.join(train_root, cls)\n",
        "        imgs, _ = load_images_from_folder(p, img_size)\n",
        "        X.extend(imgs)\n",
        "        y.extend([label_map[cls]]*len(imgs))\n",
        "        counts.append((cls, len(imgs)))\n",
        "        print(f\"Loaded {len(imgs)} images for class {cls}\")\n",
        "    X = np.array(X, dtype=np.float32)/255.0\n",
        "    y = np.array(y, dtype=np.int32)\n",
        "    print(\"Total samples:\", X.shape[0])\n",
        "    return X, y, label_map, inv_map, counts\n",
        "\n",
        "# build datasets\n",
        "X, y, label_map, inv_map, class_counts = build_train_dataset(ROOT_TRAIN, IMG_SIZE)\n",
        "num_classes = len(label_map)\n",
        "print(\"Num classes:\", num_classes)\n",
        "# check class balance snippet\n",
        "print(\"Some class counts (first 10):\", class_counts[:10])\n",
        "\n",
        "# split\n",
        "X_train, X_val, y_train_idx, y_val_idx = train_test_split(X, y, test_size=0.18, stratify=y, random_state=SEED)\n",
        "y_train = tf.keras.utils.to_categorical(y_train_idx, num_classes)\n",
        "y_val   = tf.keras.utils.to_categorical(y_val_idx, num_classes)\n",
        "print(\"Train shape:\", X_train.shape, y_train.shape, \"Val shape:\", X_val.shape, y_val.shape)\n",
        "\n",
        "# load test (infer labels from filename prefix if possible)\n",
        "def load_test(test_root, img_size=IMG_SIZE):\n",
        "    Xt=[]; yt=[]\n",
        "    for fn in sorted(os.listdir(test_root)):\n",
        "        fp = os.path.join(test_root, fn)\n",
        "        if not os.path.isfile(fp): continue\n",
        "        try:\n",
        "            img = cv2.imdecode(np.fromfile(fp, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "            if img is None: continue\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (img_size, img_size))\n",
        "            Xt.append(img)\n",
        "            # try infer label from filename \"056_...\" or \"00001.png\": use first token before _\n",
        "            label=None\n",
        "            try:\n",
        "                label = int(fn.split(\"_\")[0])\n",
        "            except:\n",
        "                label=None\n",
        "            yt.append(label)\n",
        "        except Exception as e:\n",
        "            print(\"Warning reading test file\", fp, \":\", e)\n",
        "    Xt = np.array(Xt, dtype=np.float32)/255.0\n",
        "    yt = np.array(yt, dtype=object)\n",
        "    return Xt, yt\n",
        "\n",
        "X_test_raw, y_test_guess = load_test(ROOT_TEST, IMG_SIZE)\n",
        "print(\"Raw test samples:\", X_test_raw.shape[0], \"some inferred labels:\", y_test_guess[:10])\n",
        "# Map inferred labels to training label indices; drop None\n",
        "mapped=[]\n",
        "mask=[]\n",
        "for lbl in y_test_guess:\n",
        "    if lbl is None:\n",
        "        mask.append(False); mapped.append(None)\n",
        "    else:\n",
        "        # match integer label to keys in label_map\n",
        "        found=None\n",
        "        for k in label_map:\n",
        "            try:\n",
        "                if int(k) == int(lbl):\n",
        "                    found = label_map[k]; break\n",
        "            except: continue\n",
        "        if found is None:\n",
        "            mask.append(False); mapped.append(None)\n",
        "        else:\n",
        "            mask.append(True); mapped.append(found)\n",
        "mask = np.array(mask)\n",
        "X_test = X_test_raw[mask]\n",
        "y_test_idx = np.array([m for m in mapped if m is not None], dtype=np.int32)\n",
        "y_test_onehot = tf.keras.utils.to_categorical(y_test_idx, num_classes)\n",
        "print(\"Test after mapping:\", X_test.shape[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjFaVVdghZ_8"
      },
      "source": [
        "## Model builders and callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ArgcPVMl803u"
      },
      "outputs": [],
      "source": [
        "# CELL 6: model builders and callbacks\n",
        "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "def build_cnn_model(input_shape=(IMG_SIZE,IMG_SIZE,3), num_classes=num_classes):\n",
        "    l2 = regularizers.l2(1e-4)\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
        "    x = layers.RandomRotation(0.05)(x)\n",
        "    x = layers.RandomContrast(0.1)(x)\n",
        "\n",
        "    x = layers.Conv2D(32,3,padding='same',kernel_regularizer=l2)(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(32,3,padding='same',kernel_regularizer=l2)(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D()(x); x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    x = layers.Conv2D(64,3,padding='same',kernel_regularizer=l2)(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(64,3,padding='same',kernel_regularizer=l2)(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D()(x); x = layers.Dropout(0.30)(x)\n",
        "\n",
        "    x = layers.Conv2D(128,3,padding='same',kernel_regularizer=l2)(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D()(x); x = layers.Dropout(0.40)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, kernel_regularizer=l2)(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# callbacks shared\n",
        "def get_callbacks(name_prefix=\"model\"):\n",
        "    cbs = [\n",
        "        callbacks.ModelCheckpoint(f\"{name_prefix}_best.h5\", monitor='val_accuracy', save_best_only=True, verbose=1),\n",
        "        callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
        "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1)\n",
        "    ]\n",
        "    return cbs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2vq9_JUhfsQ"
      },
      "source": [
        "## Training CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "86ETAIyW85b_",
        "outputId": "20eadb55-7fbf-4e25-e767-7016ea32584b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ random_flip (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ random_rotation                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomRotation</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ random_contrast                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomContrast</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,906</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ random_flip (\u001b[38;5;33mRandomFlip\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ random_rotation                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mRandomRotation\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ random_contrast                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mRandomContrast\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,097,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m)             │        \u001b[38;5;34m14,906\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,254,042</span> (8.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,254,042\u001b[0m (8.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,252,890</span> (8.59 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,252,890\u001b[0m (8.59 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779ms/step - accuracy: 0.2174 - loss: 3.3692\n",
            "Epoch 1: val_accuracy improved from -inf to 0.06258, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 817ms/step - accuracy: 0.2197 - loss: 3.3571 - val_accuracy: 0.0626 - val_loss: 4.1845 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.5848 - loss: 1.5962\n",
            "Epoch 2: val_accuracy did not improve from 0.06258\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 792ms/step - accuracy: 0.5854 - loss: 1.5941 - val_accuracy: 0.0626 - val_loss: 4.5059 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.7487 - loss: 1.0553\n",
            "Epoch 3: val_accuracy improved from 0.06258 to 0.07457, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 794ms/step - accuracy: 0.7488 - loss: 1.0546 - val_accuracy: 0.0746 - val_loss: 4.2126 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.8134 - loss: 0.7897\n",
            "Epoch 4: val_accuracy improved from 0.07457 to 0.13316, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 793ms/step - accuracy: 0.8136 - loss: 0.7892 - val_accuracy: 0.1332 - val_loss: 3.6975 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.8656 - loss: 0.6235\n",
            "Epoch 5: val_accuracy improved from 0.13316 to 0.22503, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 792ms/step - accuracy: 0.8655 - loss: 0.6237 - val_accuracy: 0.2250 - val_loss: 2.8199 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.8848 - loss: 0.5498\n",
            "Epoch 6: val_accuracy improved from 0.22503 to 0.34621, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 794ms/step - accuracy: 0.8848 - loss: 0.5497 - val_accuracy: 0.3462 - val_loss: 2.1563 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.9041 - loss: 0.4630\n",
            "Epoch 7: val_accuracy improved from 0.34621 to 0.64847, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 794ms/step - accuracy: 0.9041 - loss: 0.4631 - val_accuracy: 0.6485 - val_loss: 1.3065 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: 0.9210 - loss: 0.4020\n",
            "Epoch 8: val_accuracy improved from 0.64847 to 0.80027, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 796ms/step - accuracy: 0.9209 - loss: 0.4021 - val_accuracy: 0.8003 - val_loss: 0.8238 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.9436 - loss: 0.3504\n",
            "Epoch 9: val_accuracy improved from 0.80027 to 0.90413, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 794ms/step - accuracy: 0.9435 - loss: 0.3504 - val_accuracy: 0.9041 - val_loss: 0.5071 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764ms/step - accuracy: 0.9393 - loss: 0.3450\n",
            "Epoch 10: val_accuracy improved from 0.90413 to 0.95473, saving model to cnn_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 797ms/step - accuracy: 0.9394 - loss: 0.3449 - val_accuracy: 0.9547 - val_loss: 0.3397 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9399 - loss: 0.3189\n",
            "Epoch 11: val_accuracy did not improve from 0.95473\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 792ms/step - accuracy: 0.9399 - loss: 0.3188 - val_accuracy: 0.9521 - val_loss: 0.3077 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9518 - loss: 0.2939\n",
            "Epoch 12: val_accuracy did not improve from 0.95473\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 791ms/step - accuracy: 0.9519 - loss: 0.2938 - val_accuracy: 0.9481 - val_loss: 0.2706 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: 0.9611 - loss: 0.2606\n",
            "Epoch 13: val_accuracy improved from 0.95473 to 0.98269, saving model to cnn_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 792ms/step - accuracy: 0.9611 - loss: 0.2606 - val_accuracy: 0.9827 - val_loss: 0.1907 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.9649 - loss: 0.2479\n",
            "Epoch 14: val_accuracy did not improve from 0.98269\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 789ms/step - accuracy: 0.9649 - loss: 0.2480 - val_accuracy: 0.9800 - val_loss: 0.2024 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: 0.9694 - loss: 0.2465\n",
            "Epoch 15: val_accuracy improved from 0.98269 to 0.98402, saving model to cnn_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 793ms/step - accuracy: 0.9694 - loss: 0.2467 - val_accuracy: 0.9840 - val_loss: 0.1840 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.9731 - loss: 0.2313\n",
            "Epoch 16: val_accuracy did not improve from 0.98402\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 791ms/step - accuracy: 0.9731 - loss: 0.2313 - val_accuracy: 0.9800 - val_loss: 0.1852 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9651 - loss: 0.2432\n",
            "Epoch 17: val_accuracy improved from 0.98402 to 0.98668, saving model to cnn_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 792ms/step - accuracy: 0.9651 - loss: 0.2433 - val_accuracy: 0.9867 - val_loss: 0.1687 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9698 - loss: 0.2329\n",
            "Epoch 18: val_accuracy improved from 0.98668 to 0.98802, saving model to cnn_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 792ms/step - accuracy: 0.9698 - loss: 0.2329 - val_accuracy: 0.9880 - val_loss: 0.1651 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.9767 - loss: 0.2125\n",
            "Epoch 19: val_accuracy improved from 0.98802 to 0.99734, saving model to cnn_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 794ms/step - accuracy: 0.9767 - loss: 0.2126 - val_accuracy: 0.9973 - val_loss: 0.1523 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: 0.9812 - loss: 0.2053\n",
            "Epoch 20: val_accuracy did not improve from 0.99734\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 794ms/step - accuracy: 0.9811 - loss: 0.2053 - val_accuracy: 0.9920 - val_loss: 0.1604 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: 0.9790 - loss: 0.2099\n",
            "Epoch 21: val_accuracy did not improve from 0.99734\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 793ms/step - accuracy: 0.9790 - loss: 0.2099 - val_accuracy: 0.9920 - val_loss: 0.1610 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - accuracy: 0.9803 - loss: 0.2021\n",
            "Epoch 22: val_accuracy did not improve from 0.99734\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 793ms/step - accuracy: 0.9803 - loss: 0.2021 - val_accuracy: 0.9960 - val_loss: 0.1557 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9822 - loss: 0.1947\n",
            "Epoch 23: val_accuracy did not improve from 0.99734\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 791ms/step - accuracy: 0.9822 - loss: 0.1948 - val_accuracy: 0.9973 - val_loss: 0.1597 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - accuracy: 0.9877 - loss: 0.1879\n",
            "Epoch 24: val_accuracy did not improve from 0.99734\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 795ms/step - accuracy: 0.9877 - loss: 0.1879 - val_accuracy: 0.9973 - val_loss: 0.1430 - learning_rate: 5.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: 0.9923 - loss: 0.1695\n",
            "Epoch 25: val_accuracy improved from 0.99734 to 0.99867, saving model to cnn_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 792ms/step - accuracy: 0.9923 - loss: 0.1696 - val_accuracy: 0.9987 - val_loss: 0.1418 - learning_rate: 5.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: 0.9908 - loss: 0.1688\n",
            "Epoch 26: val_accuracy improved from 0.99867 to 1.00000, saving model to cnn_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 792ms/step - accuracy: 0.9907 - loss: 0.1689 - val_accuracy: 1.0000 - val_loss: 0.1411 - learning_rate: 5.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9893 - loss: 0.1726\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 791ms/step - accuracy: 0.9893 - loss: 0.1725 - val_accuracy: 0.9987 - val_loss: 0.1369 - learning_rate: 5.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764ms/step - accuracy: 0.9923 - loss: 0.1644\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 796ms/step - accuracy: 0.9923 - loss: 0.1644 - val_accuracy: 0.9987 - val_loss: 0.1372 - learning_rate: 5.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - accuracy: 0.9894 - loss: 0.1661\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 795ms/step - accuracy: 0.9894 - loss: 0.1661 - val_accuracy: 0.9973 - val_loss: 0.1345 - learning_rate: 5.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: 0.9913 - loss: 0.1595\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 795ms/step - accuracy: 0.9913 - loss: 0.1595 - val_accuracy: 0.9973 - val_loss: 0.1411 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 29.\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n",
            "✅ CNN training complete and predictions saved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Build CNN\n",
        "cnn_model = build_cnn_model()\n",
        "\n",
        "print(\"CNN summary:\")\n",
        "cnn_model.summary()\n",
        "\n",
        "# Train CNN\n",
        "hist_cnn = cnn_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=get_callbacks(\"cnn\"),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# Save CNN predictions for evaluation\n",
        "# ===============================\n",
        "\n",
        "cnn_preds_proba = cnn_model.predict(X_test)\n",
        "cnn_preds = cnn_preds_proba.argmax(axis=1)\n",
        "\n",
        "# Save for later analysis\n",
        "np.save(\"cnn_preds.npy\", cnn_preds)\n",
        "np.save(\"y_true.npy\", y_test_idx)\n",
        "\n",
        "print(\"✅ CNN training complete and predictions saved.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluting CNN Model"
      ],
      "metadata": {
        "id": "tvSA8uAlm_26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===== CNN TEST EVALUATION =====\")\n",
        "\n",
        "cnn_acc = accuracy_score(y_test_idx, cnn_preds)\n",
        "cnn_prec = precision_score(y_test_idx, cnn_preds, average='macro', zero_division=0)\n",
        "cnn_rec = recall_score(y_test_idx, cnn_preds, average='macro', zero_division=0)\n",
        "cnn_f1 = f1_score(y_test_idx, cnn_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy           : {cnn_acc:.4f}\")\n",
        "print(f\"Precision (macro)  : {cnn_prec:.4f}\")\n",
        "print(f\"Recall (macro)     : {cnn_rec:.4f}\")\n",
        "print(f\"F1-score (macro)   : {cnn_f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_idx, cnn_preds, zero_division=0))\n",
        "\n",
        "cm_cnn = confusion_matrix(y_test_idx, cnn_preds)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_cnn, cmap=\"Blues\", fmt=\"d\")\n",
        "plt.title(\"Confusion Matrix – CNN\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "def mcnemar_test(y_true, pred_a, pred_b, name_a=\"Model A\", name_b=\"Model B\"):\n",
        "    # Build contingency table\n",
        "    table = [[0, 0], [0, 0]]\n",
        "    for yt, pa, pb in zip(y_true, pred_a, pred_b):\n",
        "        if pa == yt and pb == yt:\n",
        "            table[0][0] += 1\n",
        "        elif pa == yt and pb != yt:\n",
        "            table[0][1] += 1\n",
        "        elif pa != yt and pb == yt:\n",
        "            table[1][0] += 1\n",
        "        else:\n",
        "            table[1][1] += 1\n",
        "\n",
        "    result = mcnemar(table, exact=True)\n",
        "\n",
        "    print(f\"\\nMcNemar Test: {name_a} vs {name_b}\")\n",
        "    print(\"Contingency Table:\", table)\n",
        "    print(\"p-value:\", result.pvalue)\n",
        "\n",
        "    if result.pvalue < 0.05:\n",
        "        print(\"✅ Statistically significant difference\")\n",
        "    else:\n",
        "        print(\"❌ No statistically significant difference\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_xAiQ1olnG2x",
        "outputId": "afe282b4-c8e5-4d35-85bc-28f9c9a9ad73"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== CNN TEST EVALUATION =====\n",
            "Accuracy           : 0.6740\n",
            "Precision (macro)  : 0.6929\n",
            "Recall (macro)     : 0.6864\n",
            "F1-score (macro)   : 0.6468\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92        14\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.48      0.77      0.59        60\n",
            "           3       0.79      0.79      0.79        84\n",
            "           4       0.47      0.86      0.61        58\n",
            "           5       0.41      0.36      0.38        50\n",
            "           6       0.86      0.40      0.55        30\n",
            "           7       0.35      0.28      0.31        50\n",
            "           8       1.00      0.86      0.92        14\n",
            "          10       1.00      0.97      0.98        60\n",
            "          11       0.80      0.69      0.74       130\n",
            "          12       0.69      1.00      0.81        22\n",
            "          13       0.72      0.39      0.51        92\n",
            "          14       0.83      0.83      0.83        12\n",
            "          15       1.00      0.06      0.11        36\n",
            "          16       0.76      0.97      0.85        76\n",
            "          17       1.00      0.67      0.80        84\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       1.00      1.00      1.00         2\n",
            "          21       1.00      0.50      0.67        12\n",
            "          22       1.00      0.50      0.67         8\n",
            "          23       1.00      0.60      0.75        10\n",
            "          24       0.65      1.00      0.79        26\n",
            "          25       1.00      1.00      1.00         2\n",
            "          26       1.00      0.82      0.90       134\n",
            "          27       0.75      0.75      0.75        24\n",
            "          28       0.96      0.76      0.85        68\n",
            "          29       0.93      1.00      0.96        26\n",
            "          30       0.60      0.88      0.71        34\n",
            "          31       0.60      0.67      0.63        18\n",
            "          32       1.00      1.00      1.00         2\n",
            "          34       0.00      0.00      0.00         8\n",
            "          35       0.31      0.96      0.47        46\n",
            "          36       1.00      1.00      1.00        12\n",
            "          37       0.75      0.46      0.57        26\n",
            "          38       0.40      0.10      0.16        40\n",
            "          39       0.00      0.00      0.00        30\n",
            "          40       0.50      1.00      0.67         8\n",
            "          41       0.00      0.00      0.00         8\n",
            "          42       0.39      0.78      0.52        18\n",
            "          43       0.65      0.22      0.33       116\n",
            "          44       0.00      0.00      0.00        24\n",
            "          45       0.14      1.00      0.25         2\n",
            "          46       0.14      1.00      0.25        14\n",
            "          47       1.00      1.00      1.00        10\n",
            "          48       1.00      1.00      1.00         6\n",
            "          49       0.52      0.57      0.55        42\n",
            "          50       0.83      0.50      0.62        20\n",
            "          51       1.00      1.00      1.00         4\n",
            "          52       0.50      0.67      0.57        30\n",
            "          53       1.00      1.00      1.00         2\n",
            "          54       0.98      0.99      0.98       176\n",
            "          55       1.00      0.69      0.82        58\n",
            "          56       0.68      0.75      0.71        40\n",
            "          57       0.67      1.00      0.80         4\n",
            "\n",
            "    accuracy                           0.67      1994\n",
            "   macro avg       0.69      0.69      0.65      1994\n",
            "weighted avg       0.74      0.67      0.67      1994\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2pvlhXmiWNF"
      },
      "source": [
        "## Imports for classical Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SGfz6-1HW7UQ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "from statsmodels.stats.contingency_tables import mcnemar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiGUtZ6xicUv"
      },
      "source": [
        "## Classical model ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKWaiTfWW8MR",
        "outputId": "5e40c212-abab-4442-b66c-4616b6e0b9b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened shape: (3419, 3072)\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Feature vector shape: (3419, 32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# preprocessing data for classical model\n",
        "def preprocess_for_classical_ml(X, target_size=32):\n",
        "    X_small = []\n",
        "    for img in X:\n",
        "        img_resized = cv2.resize(\n",
        "            img, (target_size, target_size),\n",
        "            interpolation=cv2.INTER_LINEAR\n",
        "        )\n",
        "        X_small.append(img_resized.flatten())\n",
        "    return np.array(X_small, dtype=np.float32)\n",
        "\n",
        "X_train_flat = preprocess_for_classical_ml(X_train)\n",
        "X_val_flat   = preprocess_for_classical_ml(X_val)\n",
        "X_test_flat  = preprocess_for_classical_ml(X_test)\n",
        "\n",
        "print(\"Flattened shape:\", X_train_flat.shape)\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_feature_encoder(input_dim):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(32, activation='relu')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "encoder = build_feature_encoder(X_train_flat.shape[1])\n",
        "\n",
        "\n",
        "\n",
        "X_train_feat = encoder.predict(X_train_flat)\n",
        "X_test_feat  = encoder.predict(X_test_flat)\n",
        "\n",
        "print(\"Feature vector shape:\", X_train_feat.shape)\n",
        "\n",
        "svm = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "svm_params = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 0.01, 0.001]\n",
        "}\n",
        "\n",
        "svm_grid = GridSearchCV(\n",
        "    svm, svm_params,\n",
        "    cv=5, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "\n",
        "svm_grid.fit(X_train_feat, y_train_idx)\n",
        "svm_best = svm_grid.best_estimator_\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 20, 40],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "rf_grid = GridSearchCV(\n",
        "    rf, rf_params,\n",
        "    cv=5, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_grid.fit(X_train_feat, y_train_idx)\n",
        "rf_best = rf_grid.best_estimator_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating classical ml models\n",
        "\n"
      ],
      "metadata": {
        "id": "gLcFuZ_Hl1bb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGIrFm4NXfZ0"
      },
      "outputs": [],
      "source": [
        "svm_preds = svm_best.predict(X_test_feat)\n",
        "rf_preds  = rf_best.predict(X_test_feat)\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred):\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision (macro):\", precision_score(y_true, y_pred, average='macro'))\n",
        "    print(\"Recall (macro):\", recall_score(y_true, y_pred, average='macro'))\n",
        "    print(\"F1-score (macro):\", f1_score(y_true, y_pred, average='macro'))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
        "\n",
        "evaluate_model(\"SVM\", y_test_idx, svm_preds)\n",
        "evaluate_model(\"Random Forest\", y_test_idx, rf_preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mcnemar test"
      ],
      "metadata": {
        "id": "7RrXWaewmNEQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8S4C2aHXiMn"
      },
      "outputs": [],
      "source": [
        "def mcnemar_test(y_true, pred1, pred2):\n",
        "    table = [[0, 0], [0, 0]]\n",
        "    for yt, p1, p2 in zip(y_true, pred1, pred2):\n",
        "        if p1 == yt and p2 == yt:\n",
        "            table[0][0] += 1\n",
        "        elif p1 == yt and p2 != yt:\n",
        "            table[0][1] += 1\n",
        "        elif p1 != yt and p2 == yt:\n",
        "            table[1][0] += 1\n",
        "        else:\n",
        "            table[1][1] += 1\n",
        "\n",
        "    result = mcnemar(table, exact=True)\n",
        "    print(\"McNemar p-value:\", result.pvalue)\n",
        "\n",
        "mcnemar_test(y_test_idx, svm_preds, rf_preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ploting confusion matrix"
      ],
      "metadata": {
        "id": "B8BWaKAtmR_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "7KTbYUvhXjuH",
        "outputId": "e5940e8f-e5d9-40d9-a9ff-abeca78ae890"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'svm_preds' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1623839253.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplot_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SVM Confusion Matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplot_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Random Forest Confusion Matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'svm_preds' is not defined"
          ]
        }
      ],
      "source": [
        "def plot_cm(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, cmap='Blues', fmt='d')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "plot_cm(y_test_idx, svm_preds, \"SVM Confusion Matrix\")\n",
        "plot_cm(y_test_idx, rf_preds, \"Random Forest Confusion Matrix\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparative analysis"
      ],
      "metadata": {
        "id": "2DKuKpQBmYo0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBu3OTutfQGz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"CNN\", \"SVM\", \"Random Forest\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test_idx, cnn_preds),\n",
        "        accuracy_score(y_test_idx, svm_preds),\n",
        "        accuracy_score(y_test_idx, rf_preds)\n",
        "    ],\n",
        "    \"Precision (macro)\": [\n",
        "        precision_score(y_test_idx, cnn_preds, average='macro', zero_division=0),\n",
        "        precision_score(y_test_idx, svm_preds, average='macro', zero_division=0),\n",
        "        precision_score(y_test_idx, rf_preds, average='macro', zero_division=0)\n",
        "    ],\n",
        "    \"Recall (macro)\": [\n",
        "        recall_score(y_test_idx, cnn_preds, average='macro', zero_division=0),\n",
        "        recall_score(y_test_idx, svm_preds, average='macro', zero_division=0),\n",
        "        recall_score(y_test_idx, rf_preds, average='macro', zero_division=0)\n",
        "    ],\n",
        "    \"F1-score (macro)\": [\n",
        "        f1_score(y_test_idx, cnn_preds, average='macro', zero_division=0),\n",
        "        f1_score(y_test_idx, svm_preds, average='macro', zero_division=0),\n",
        "        f1_score(y_test_idx, rf_preds, average='macro', zero_division=0)\n",
        "    ]\n",
        "})\n",
        "\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Models"
      ],
      "metadata": {
        "id": "mNKvBsEamcqQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gHNxSCP9NES"
      },
      "outputs": [],
      "source": [
        "# CELL 10: save artifacts to Drive for report & reproducibility\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/traffic_model_results\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# --- Save CNN ---\n",
        "cnn_model.save(os.path.join(OUT_DIR, \"cnn_model.h5\"))\n",
        "np.save(os.path.join(OUT_DIR, \"cnn_preds.npy\"), cnn_preds)\n",
        "\n",
        "# --- Save classical ML models ---\n",
        "import joblib\n",
        "joblib.dump(svm_best, os.path.join(OUT_DIR, \"svm_model.joblib\"))\n",
        "joblib.dump(rf_best, os.path.join(OUT_DIR, \"rf_model.joblib\"))\n",
        "\n",
        "np.save(os.path.join(OUT_DIR, \"svm_preds.npy\"), svm_preds)\n",
        "np.save(os.path.join(OUT_DIR, \"rf_preds.npy\"), rf_preds)\n",
        "\n",
        "# --- Save ground truth ---\n",
        "np.save(os.path.join(OUT_DIR, \"y_true.npy\"), y_test_idx)\n",
        "\n",
        "print(\"Saved all models and predictions to:\", OUT_DIR)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}